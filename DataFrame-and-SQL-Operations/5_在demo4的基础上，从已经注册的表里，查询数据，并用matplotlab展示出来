python版，streaming操作sql，同时可以使用matplotlab画图

from __future__ import print_function
import os
import sys
import json
from pyspark import SparkContext
from pyspark.streaming import StreamingContext
from pyspark.sql import SQLContext, Row

def getSqlContextInstance(sparkContext):
    if ('sqlContextSingletonInstance' not in globals()):
        globals()['sqlContextSingletonInstance'] = SQLContext(sparkContext)
    return globals()['sqlContextSingletonInstance']

def process(time, rdd):
        print("========= %s =========" % str(time))
        if (rdd.count() != 0):
            try:
                value = rdd.collect()
                sqlContext = getSqlContextInstance(rdd.context)
                for (table_name, table_set) in value:
                    registerDBTable(table_name, table_set, sqlContext)
                getInfo = sqlContext.sql("\
                          SELECT min(ss.SubmissionTime), max(ss.SubmissionTime) FROM SparkListenerJobStart as ss \
                          ")
                minSubmissionTime = getInfo.collect()[0][0]
                getInfo = sqlContext.sql("\
                          SELECT ss.JobID, ((se.CompletionTime - ss.SubmissionTime)/1000) as duration, ((ss.SubmissionTime - %d)/1000) as submit \
                          FROM SparkListenerJobStart ss, SparkListenerJobEnd se \
                          Where ss.JobID = se.JobID AND se.JobResult.Result = 'JobSucceeded' \
                          Order by duration DESC, submit \
                          " % minSubmissionTime)
                %matplotlib inline
                import numpy as np
                import matplotlib.pyplot as plt

                data = getInfo.collect()
                x = [d[1] for d in data]
                y= [d[2] for d in data]

                fig_size = [4, 2]
                plt.rcParams["figure.figsize"] = fig_size
                plt.scatter(x, y)
                plt.show() 
            except:
                pass

def getEvent(item):
  json_format = json.loads(item)
  key = json_format['Event']
  value = json.dumps(json_format).replace(' ', '')
  return (key, value)

def registerDBTable(table_name, table_set, sqlContext):
  lineRdd = sc.parallelize(table_set)
  sqlContext.jsonRDD(lineRdd).registerTempTable(table_name)
  return

ssc = StreamingContext(sc, 4)

lines = ssc.textFileStream("/usr/local/src/bluemix_ipythonspark_141/provision/xcdong/data")
words = lines.map(lambda line: getEvent(line)).groupByKey()
windowDStream = words.window(86400, 4)
windowDStream.foreachRDD(process)
ssc.start()

ssc.awaitTermination()
