每10秒计算一次，前15s计算的值
object WindowCounter { 
def main(args: Array[String]) {
  if (args.length < 4) {
  System.err.printIn("Usage: NetworkWordCount <master> <hostname> <port> <interval> M + "<windowLength> <slidelnterval>\n" +
  "In local mode, <master> should be 'local[n]' with n > 1")
  System.exit(1)
}

StreamingExamples.setStreamingLogLevels()

// Create the context with a 1 second batch size
val ssc = new StreamingContext(args(0), "WindowCounter", Seconds{args(3).tolnt),
System.getenv("SPARK_HOME"), StreamingContext.jarOfClass{this.getClass))

 ssc .checkpoint {".")

// Create a NetworklnputDStream on target ip:port and count the
// words in input stream of \n delimited text (eg. generated by 'nc')
val lines = ssc.socketTextStream(args(1), args(2).tolnt, StorageLevel.MEMORY_ONLY_SER)

val words = tines.flatMap(_.split(" "))

//val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_, Seconds(30), Seconds(12)) //第一个参数是window的长度。第二个参数是多久计算一次，cannot do this，这样做会提醒类型不对
//val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow((x : Int, y : Int) => x + y, Seconds(30), Seconds(12))//上面这种不对，应该这样，但是调用这个api，实际是调用了最低效的那种方式

val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_,  _-_, Seconds(args(4).tolnt), Seconds(args(5).toInt))//这种相当于调用最优化的方式
//对所有的词频排序，sortByKey是对单个的RDD进行操作，而transform(_.sortByKey(false)}，是对这个dsream中的所有RDD应用这个fun()
val sortedWordCount = wordCounts.map{case (char, count) => (count, char)}. transform(_.sortByKey(false)}.map{case (char,count) => (count,char)}

//val wordCounts ■ words.map(x -> (x , 1)). reduceByKeyAndWindowSeconds(30))
//va【v/orc/Counts ■ ■> fx , •• Int, y •• IrrtJ x + Seconc/sfG八 Seca
//val wordCounts - y/〇rds.map(x -> (.< , 1)). reduceByKeyindWindowf _+_j Seconds(6), Seconds(6))
//val wordCounts ■ words.map(x -> (x , 1)) ,reduceByKey(_+_)

wordCounts.print()
//sortedWordCount.print()
ssc.startO
ssc.awaitTerminationO

对应参数：
local[2] localhost 9999 5 15 10,每10s中计算一下前15秒钟的数据，dstream自己的间隔是5秒钟
